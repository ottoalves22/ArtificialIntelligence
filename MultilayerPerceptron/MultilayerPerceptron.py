# -*- coding: utf-8 -*-
"""MultiLayer Perceptron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y7ZxSfC6JngB-BtSuidurc1Z7cggFzVZ

#***Não esqueça de adicionar os arquivos de dados:***
* caracteres-limpo.csv
* caracteres-ruido.csv
* caracteres-ruido20.csv

# Bibliotecas
* Pandas 
* Numpy

Otto Alves - NUSP 10843361
Victor Nicacio - NUSP 10856737

"""

import numpy as np
import pandas as pd

"""# Classe MLP"""


class MLP:
    def __init__(self, entrada=63, escondida=[9], saida=7):
        #
        # Construtor da classe MLP, que implementa a arquitetura Multilayer Perceptron
        #

        self.entradas = entrada  # Atribui o parametro entrada, por padrão tem 67 neuronios
        self.escondida = escondida  # Atribui o parametro escondida, por padrão tem 9 neuronios
        self.saida = saida  # Atribui o parametro saida, por padrão tem 7 neuronios

        camadas = [self.entradas] + self.escondida + [self.saida]  # representação das camadas da rede

        self.pesos = []
        for i in range(len(camadas) - 1):
            w = np.random.rand(camadas[i], camadas[i + 1])  # Gerando a matriz de pesos com valores aleatórios
            self.pesos.append(w)

        self.ativacoes = []
        for i in range(len(camadas)):
            temp = np.zeros(camadas[i])  # Gerando a matriz de ativações zerada
            self.ativacoes.append(temp)

        self.derivadas = []
        for i in range(len(camadas) - 1):
            aux = np.zeros((camadas[i], camadas[i + 1]))  # Gerando a matriz de derivadas zerada
            self.derivadas.append(aux)

    def sigmoide(self, t):
        #
        # Função Logistica Sigmoide
        #

        return 1 / (1 + np.exp(-t))

    def sigmoide_derivada(self, t):
        #
        # Derivada da Função Logistica Sigmoide
        #

        return t * (1.0 - t)

    def feed_foward(self, entrada):
        ativacao = entrada  # Atribui os valores de entrada em valores de ativação
        self.ativacoes[0] = entrada

        for i, w in enumerate(self.pesos):
            temp = np.dot(ativacao, w)  # Multiplicação entre a matriz de pesos da rede com os valores de ativação
            ativacao = self.sigmoide(temp)  # Aplicando a função de ativação da rede no valor de net
            self.ativacoes[i + 1] = ativacao  # contabiliza os valores de ativação

        return ativacao

    def back_propagation(self, erro):
        for i in reversed(range(len(self.derivadas))):  # Iterando entre as camadas da rede, de frente para tras
            ativacoes = self.ativacoes[i + 1]
            delta = erro * self.sigmoide_derivada(
                ativacoes)  # Multiplicação do erro pela derivada da função de ativação
            delta_transformada = delta.reshape(delta.shape[0], -1).T
            ativacao = self.ativacoes[i]
            ativacao = ativacao.reshape(ativacao.shape[0], -1)

            self.derivadas[i] = np.dot(ativacao,
                                       delta_transformada)  # Matriz de derivadas recebe a multiplicação entre o valor de ativação atual e delta

            erro = np.dot(delta, self.pesos[i].T)

    def gradiente_descendente(self, taxa_erro):
        #
        # Otimizando a função de erro e atualizando os pesos a partir da taxa de erro
        #

        for i in range(len(self.pesos)):
            pesos = self.pesos[i]
            derivadas = self.derivadas[i]
            pesos += derivadas * taxa_erro
            # print(f'Atualizando w{i} {pesos}\n')
            logger(f'Atualizando w{i} {pesos}\n', "pesos_grad_desc.txt")

    def eqm(self, target, saida):
        #
        # Calcula o erro quadratico medio
        #

        return np.average((target - saida) ** 2)

    def treinamento(self, entradas, targets, taxa_erro, epocas=1000, threshold=0.1):
        #
        # Processa o treinamento da rede se baseando e dois fatores:
        #     Epocas - por padrão é 2500
        #     Threshold - por padrão é 0.1
        #

        somatorio_erros = 2 * threshold
        epoca = 0
        while somatorio_erros > threshold:  # Loop via threshold
            # for epoca in range(epocas): # Loop via epocas
            somatorio_erros = 0
            for entrada, target in zip(entradas, targets):
                saida = self.feed_foward(entrada / np.linalg.norm(entrada))
                erro = target - saida
                self.back_propagation(erro)
                self.gradiente_descendente(taxa_erro)
                somatorio_erros += self.eqm(target, saida)
            logger(f'Erro {somatorio_erros / len(entradas)} na epoca {epoca} \n', 'erros.txt')
            print(f'Erro {somatorio_erros / len(entradas)} na epoca {epoca} \n')
            epoca += 1
        logger(f'Pesos finais:\n {self.pesos} \n', 'pesos_finais.txt')

    def predizer(self, x_teste, base):
        #
        # Processa os testes de validação da rede
        #

        resultado = self.feed_foward(x_teste)
        logger_predicao(resultado, base)
        return resultado


"""# Funções Auxiliares"""


def matriz_confusao_multiclasse(preditos, targets):
    matriz = [[0 for i in range(7)] for j in range(
        7)]  # inicia uma matriz de zeros com 7 linhas e 7 colunas uma vez que sao usados caracteres de A ate G
    resultado = []
    for i in range(len(preditos)):
        resultado.append(contabilizar(preditos[i]))  # adiciona resultados do processamento em termos de caracter

    for i in range(len(targets)):  # executara de acordo com a quantidade de targets
        d = resultado[i].index(1)  # pega a posicao do arranjo que indica o resultado em caracter
        j = targets[i].index(1)  # pega a posicao do arranjo de rotulos que indica o tipo de caracter esperado
        if d == j:  # se forem iguais, o valor foi previsto conforme seu rotulo
            matriz[j][j] += 1
        else:  # previsto equivocadamente
            matriz[d][j] += 1
    matriz_final = pd.DataFrame(matriz, index=['A', 'B', 'C', 'D', 'E', 'F', 'G'],
                                columns=['A', 'B', 'C', 'D', 'E', 'F',
                                         'G'])  # criacao de um dataset para exibir a matriz de confusao com os rotulos previstos e reais
    logger(f'Matriz de Confusão: \n{matriz_final}\n', 'resultado.txt')
    return matriz_final


def contabilizar(resultados):  # traz resultados em termos de caracter para cada resultado da mlp
    # posicoes das previsoes ['A', 'B', 'C', 'D', 'E', 'F', 'G']
    previsoes = [0, 0, 0, 0, 0, 0, 0]
    for i in range(
            len(resultados)):  # itera pelo array contendo resultado da MLP, ate encontrar a posicao respectiva a letra
        if resultados[i] == max(resultados):
            previsoes[i] += 1  # atribui o valor indicador
    return previsoes


def precisao_matriz_confusao(rotulos,
                             matriz_conf):  # verdadeiros_positivos / (verdadeiros_positivos + falsos_positivos)
    coluna = matriz_conf.iloc[:, rotulos]  # corta verticalmente e pega valores ate coluna rotulos especificada
    return matriz_conf.iloc[rotulos, rotulos] / coluna.sum()


def recall_matriz_conf(rotulos, matriz_conf):  # verdadeiros_positivos / (verdadeiros_positivos + falsos_negativos)
    linha = matriz_conf.iloc[rotulos, :]  # corta horizontalmente e pega valores da linha rotulos especificada
    return matriz_conf.iloc[rotulos, rotulos] / linha.sum()


def precisao_media(matriz):  # proporção de identificações positivas corretas por classe de caracter
    linhas, colunas = matriz.shape
    soma_precisao = 0
    for rotulo in range(linhas):  # calcula a precisao para cada classe de caracter
        soma_precisao += precisao_matriz_confusao(rotulo, matriz)
    return soma_precisao / linhas


def recall_medio(matriz):  # taxa de acerto entre positivos reais
    linhas, colunas = matriz.shape
    soma_recalls = 0
    for rotulo in range(linhas):  # calcula o recall para cada classe de caracter
        soma_recalls += recall_matriz_conf(rotulo, matriz)
    return soma_recalls / linhas


def acuracia(matriz):  # taxa de reconhecimento; fracao de predicoes corretas
    # (verdadeiros_positivos + verdadeiros_negativos) / (verdadeiros_positivos + falsos_positivos + verdadeiros_negativos + falsos_negativos)
    soma_diagonal = np.trace(matriz)  # soma os valores diagonais da matriz (corretos)
    soma_total_elementos = matriz.sum()  # soma quantidade total de predicoes
    return soma_diagonal / soma_total_elementos  # (valores corretos)/(total valores)


def estatisticas_matriz_confusao(
        matriz):  # printa no terminal a matriz de confusão resultante, precisao, recall e acuracia
    aux = ['A', 'B', 'C', 'D', 'E', 'F', 'G']
    print("Rotulo    Precisao  Revocação")
    for i in range(7):
        print(f"{aux[i]} {precisao_matriz_confusao(i, matriz):9.2f} \
              {recall_matriz_conf(i, matriz):6.3f}")

    print("Precisão total:", precisao_media(matriz))
    print("Recall total:", recall_medio(matriz))
    print("Acuracia total:", acuracia(matriz))


def separa_colunas(entrada: pd.DataFrame, linhas, col):  # funcao para separar entradas e rotulos no CSV de entrada
    target = []
    saida = []
    tgt = None
    arr = None
    for i in range(linhas):
        aux1 = []
        aux2 = []
        for j in range(col):
            if j < 63:
                aux1.append(entrada[j][i])  # monta aux 1 da lista da letra
            else:
                aux2.append(entrada[j][i])  # monta aux 2 da lista de label
        arr = np.array(aux1)
        arr = arr.tolist()
        tgt = aux2

        saida.append(arr)
        target.append(tgt)

    return saida, target  # retornam dois arranjos, um arranjo de arranjos com os caracteres e outro arranjo de arranjos com os rotulos


def logger(mensagem, arquivo):  # escreve texto mensagem no final do arquivo
    file = open(arquivo, "a")
    file.write(mensagem)
    file.close()


def logger_predicao(resultado,
                    base):  # escreve arquivo de resultado separando cada neuronio de saida pareado com sua respectiva letra
    aux = ['A', 'B', 'C', 'D', 'E', 'F', 'G']
    logger(f"Predições no CSV {base}:\n", "resultado.txt")
    for i in range(linhas_execucao):
        for j in range(7):
            logger(f"\n{resultado[i][j]} {aux[j]} \n", "resultado.txt")
        logger(f"------------------------------------", "resultado.txt")


"""# Execução"""

# Definindo o dataset de entrada e labels para o treinamento
data_input = pd.read_csv('caracteres-limpo.csv', header=None, usecols=[i for i in range(70)])
linhas_treinamento = 21
colunas = 70
X, labels = separa_colunas(data_input, linhas_treinamento, colunas)  # x numero de linhas  y num colunas
entradas = np.array(X)
targets = np.array(labels)

# Criando um objeto do tipo MLP, com os parametros padrões da rede
mlp = MLP()

# Documento com a arquitetura basica da rede
logger(f' Neuronios de Entrada = {mlp.entradas} \n \
Neuronios Escondidos = {mlp.escondida}\n \
Neuronios de Saida = {mlp.saida}\n \
Função de Ativação: 1 / (1 + np.exp(-t))\n \
Derivada da Função de Ativação: t * (1.0 - t)', 'arquitetura_rede.txt')

# Documento com os pesos iniciais da rede
[logger(f'{str(i)} \n', 'pesos_iniciais.txt') for i in mlp.pesos]

# Chamando a função de treinamento para as entradas e alvos definidos
mlp.treinamento(entradas, targets, 0.1)

"""# Predição para caracteres ruidosos 1"""

# Definindo o dataset de entrada e labels para o primeiro teste
entrada_execucao = pd.read_csv('caracteres-ruido.csv', header=None, usecols=[i for i in range(70)])
linhas_execucao = 21
X_teste, labels_teste = separa_colunas(entrada_execucao, linhas_execucao, colunas)
entradas = np.array(X_teste)

resultados1 = mlp.predizer(entradas, 'caraceteres-ruido.csv')

matriz1 = matriz_confusao_multiclasse(resultados1, labels_teste)

estatisticas_matriz_confusao(matriz1)

"""# Predição para caracteres ruidosos 2"""

# Definindo o dataset de entrada e labels para o segundo teste
entrada_execucao = pd.read_csv('caracteres_ruido20.csv', header=None, usecols=[i for i in range(70)])
linhas_execucao = 21
X_teste, labels_teste = separa_colunas(entrada_execucao, linhas_execucao, colunas)
entradas = np.array(X_teste)

resultados2 = mlp.predizer(entradas, 'caraceteres_ruido20.csv')

matriz2 = matriz_confusao_multiclasse(resultados2, labels_teste)

estatisticas_matriz_confusao(matriz2)
